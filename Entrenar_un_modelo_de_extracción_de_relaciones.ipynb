{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Entrenar un modelo de extracción de relaciones.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kL_mCvPuc-fT"
      },
      "source": [
        "- Entrenar un modelo de extracción de entidades y relaciones \n",
        "\n",
        "Recordemos que son ideas entrelazadas y antes de pasar a extraer relaciones, primero es necesario pensar en las entidades a las cuales les queremos asignar una relación.\n",
        "\n",
        "> La idea original es planteada en el siguiente articulo:\n",
        "\n",
        "https://towardsdatascience.com/how-to-train-a-joint-entities-and-relation-extraction-classifier-using-bert-transformer-with-spacy-49eb08d91b5c\n",
        "\n",
        "Nosotros hacemos las modificaciones pertinentes para entrenar nuestra propia base de datos en idioma español"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VsOtdxXWZau"
      },
      "source": [
        "# Elementos a instalar"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Los de extraccion de entidades\n",
        "!pip install -U spacy==3.2.4\n",
        "!python -m spacy download es_dep_news_trf\n",
        "!pip install git+https://github.com/explosion/spacy-transformers\n",
        "#y unas paqueterias extra\n",
        "!pip install -U pip setuptools wheel\n",
        "!python -m spacy project clone tutorials/rel_component\n",
        "#Suponemos que rel_component se intalo en /content/drive/MyDrive/modelos_estancia/rel_component\n",
        "#de no ser el caso, solo tenener las consideraciones de donde tenemos la carpeta rel_component"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zX7OqHs6nlyA",
        "outputId": "f63c4988-21da-48b9-c18b-a63481ba35f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting spacy==3.2.4\n",
            "  Downloading spacy-3.2.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.4) (3.0.6)\n",
            "Collecting langcodes<4.0.0,>=3.2.0\n",
            "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 45.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.4) (0.9.1)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 34.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.4) (1.0.7)\n",
            "Collecting typing-extensions<4.0.0.0,>=3.7.4\n",
            "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.4) (7.1.2)\n",
            "Collecting typer<0.5.0,>=0.3.0\n",
            "  Downloading typer-0.4.1-py3-none-any.whl (27 kB)\n",
            "Collecting srsly<3.0.0,>=2.4.1\n",
            "  Downloading srsly-2.4.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (457 kB)\n",
            "\u001b[K     |████████████████████████████████| 457 kB 45.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.4) (2.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.4) (21.3)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.8\n",
            "  Downloading spacy_legacy-3.0.9-py2.py3-none-any.whl (20 kB)\n",
            "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
            "  Downloading spacy_loggers-1.0.2-py3-none-any.whl (7.2 kB)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.4) (1.21.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.4) (4.64.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.4) (2.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.4) (57.4.0)\n",
            "Collecting thinc<8.1.0,>=8.0.12\n",
            "  Downloading thinc-8.0.16-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (660 kB)\n",
            "\u001b[K     |████████████████████████████████| 660 kB 73.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.4) (0.4.1)\n",
            "Collecting pathy>=0.3.5\n",
            "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 438 kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.2.4) (2.23.0)\n",
            "Collecting catalogue<2.1.0,>=2.0.6\n",
            "  Downloading catalogue-2.0.7-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy==3.2.4) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy==3.2.4) (3.0.9)\n",
            "Collecting smart-open<6.0.0,>=5.0.0\n",
            "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.4) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.4) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.4) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.4) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy==3.2.4) (2.0.1)\n",
            "Installing collected packages: typing-extensions, catalogue, typer, srsly, smart-open, pydantic, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, spacy\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.2.0\n",
            "    Uninstalling typing-extensions-4.2.0:\n",
            "      Successfully uninstalled typing-extensions-4.2.0\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Attempting uninstall: smart-open\n",
            "    Found existing installation: smart-open 6.0.0\n",
            "    Uninstalling smart-open-6.0.0:\n",
            "      Successfully uninstalled smart-open-6.0.0\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0+zzzcolab20220506162203 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\u001b[0m\n",
            "Successfully installed catalogue-2.0.7 langcodes-3.3.0 pathy-0.6.1 pydantic-1.8.2 smart-open-5.2.1 spacy-3.2.4 spacy-legacy-3.0.9 spacy-loggers-1.0.2 srsly-2.4.3 thinc-8.0.16 typer-0.4.1 typing-extensions-3.10.0.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "typing_extensions"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting es-dep-news-trf==3.2.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_dep_news_trf-3.2.0/es_dep_news_trf-3.2.0-py3-none-any.whl (410.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 410.2 MB 34 kB/s \n",
            "\u001b[?25hCollecting spacy-transformers<1.2.0,>=1.1.2\n",
            "  Downloading spacy_transformers-1.1.5-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 130 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from es-dep-news-trf==3.2.0) (3.2.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-dep-news-trf==3.2.0) (21.3)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-dep-news-trf==3.2.0) (3.10.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-dep-news-trf==3.2.0) (3.0.6)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-dep-news-trf==3.2.0) (1.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-dep-news-trf==3.2.0) (2.23.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-dep-news-trf==3.2.0) (2.0.7)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-dep-news-trf==3.2.0) (2.4.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-dep-news-trf==3.2.0) (1.0.7)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-dep-news-trf==3.2.0) (3.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-dep-news-trf==3.2.0) (2.0.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-dep-news-trf==3.2.0) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-dep-news-trf==3.2.0) (1.21.6)\n",
            "Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-dep-news-trf==3.2.0) (7.1.2)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-dep-news-trf==3.2.0) (0.6.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-dep-news-trf==3.2.0) (0.4.1)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-dep-news-trf==3.2.0) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-dep-news-trf==3.2.0) (57.4.0)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-dep-news-trf==3.2.0) (8.0.16)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-dep-news-trf==3.2.0) (0.9.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-dep-news-trf==3.2.0) (2.11.3)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-dep-news-trf==3.2.0) (3.3.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->es-dep-news-trf==3.2.0) (1.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.3.0,>=3.2.0->es-dep-news-trf==3.2.0) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->es-dep-news-trf==3.2.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->es-dep-news-trf==3.2.0) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->es-dep-news-trf==3.2.0) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->es-dep-news-trf==3.2.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->es-dep-news-trf==3.2.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->es-dep-news-trf==3.2.0) (1.24.3)\n",
            "Collecting transformers<4.18.0,>=3.4.0\n",
            "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 10.1 MB/s \n",
            "\u001b[?25hCollecting spacy-alignments<1.0.0,>=0.7.2\n",
            "  Downloading spacy_alignments-0.8.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 44.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers<1.2.0,>=1.1.2->es-dep-news-trf==3.2.0) (1.11.0+cu113)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<4.18.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->es-dep-news-trf==3.2.0) (4.11.3)\n",
            "Collecting tokenizers!=0.11.3,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 46.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<4.18.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->es-dep-news-trf==3.2.0) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 41.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<4.18.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->es-dep-news-trf==3.2.0) (3.7.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 4.4 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 63.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.3.0,>=3.2.0->es-dep-news-trf==3.2.0) (2.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<4.18.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->es-dep-news-trf==3.2.0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<4.18.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->es-dep-news-trf==3.2.0) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=f361103a53996897c25f2c49712b3e208bff2fc4dddccc77561e03ea3db3d4ea\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers, spacy-alignments, spacy-transformers, es-dep-news-trf\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed es-dep-news-trf-3.2.0 huggingface-hub-0.7.0 pyyaml-6.0 sacremoses-0.0.53 spacy-alignments-0.8.5 spacy-transformers-1.1.5 tokenizers-0.12.1 transformers-4.17.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_dep_news_trf')\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/explosion/spacy-transformers\n",
            "  Cloning https://github.com/explosion/spacy-transformers to /tmp/pip-req-build-cxiw6d2s\n",
            "  Running command git clone -q https://github.com/explosion/spacy-transformers /tmp/pip-req-build-cxiw6d2s\n",
            "Requirement already satisfied: spacy<4.0.0,>=3.1.3 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers==1.1.5) (3.2.4)\n",
            "Requirement already satisfied: transformers<4.19.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers==1.1.5) (4.17.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers==1.1.5) (1.11.0+cu113)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers==1.1.5) (2.4.3)\n",
            "Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers==1.1.5) (0.8.5)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers==1.1.5) (2.0.7)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers==1.1.5) (1.0.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers==1.1.5) (21.3)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers==1.1.5) (8.0.16)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers==1.1.5) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers==1.1.5) (57.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers==1.1.5) (2.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers==1.1.5) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers==1.1.5) (1.21.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers==1.1.5) (2.11.3)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers==1.1.5) (0.6.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers==1.1.5) (4.64.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers==1.1.5) (3.3.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers==1.1.5) (1.8.2)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers==1.1.5) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers==1.1.5) (0.9.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers==1.1.5) (3.0.9)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers==1.1.5) (3.0.6)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers==1.1.5) (3.10.0.2)\n",
            "Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers==1.1.5) (7.1.2)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers==1.1.5) (0.4.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<4.0.0,>=3.1.3->spacy-transformers==1.1.5) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<4.0.0,>=3.1.3->spacy-transformers==1.1.5) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<4.0.0,>=3.1.3->spacy-transformers==1.1.5) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.1.3->spacy-transformers==1.1.5) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.1.3->spacy-transformers==1.1.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.1.3->spacy-transformers==1.1.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.1.3->spacy-transformers==1.1.5) (2.10)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<4.19.0,>=3.4.0->spacy-transformers==1.1.5) (4.11.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<4.19.0,>=3.4.0->spacy-transformers==1.1.5) (0.0.53)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers<4.19.0,>=3.4.0->spacy-transformers==1.1.5) (0.7.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<4.19.0,>=3.4.0->spacy-transformers==1.1.5) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<4.19.0,>=3.4.0->spacy-transformers==1.1.5) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<4.19.0,>=3.4.0->spacy-transformers==1.1.5) (0.12.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<4.19.0,>=3.4.0->spacy-transformers==1.1.5) (3.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<4.0.0,>=3.1.3->spacy-transformers==1.1.5) (2.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<4.19.0,>=3.4.0->spacy-transformers==1.1.5) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<4.19.0,>=3.4.0->spacy-transformers==1.1.5) (1.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-22.1.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (57.4.0)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-62.3.2-py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 48.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (0.37.1)\n",
            "Installing collected packages: setuptools, pip\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.4.0\n",
            "    Uninstalling setuptools-57.4.0:\n",
            "      Successfully uninstalled setuptools-57.4.0\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0+zzzcolab20220506162203 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed pip-22.1.1 setuptools-62.3.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Cloned 'tutorials/rel_component' from explosion/projects\u001b[0m\n",
            "/content/rel_component\n",
            "\u001b[38;5;2m✔ Your project is now ready!\u001b[0m\n",
            "To fetch the assets, run:\n",
            "python -m spacy project assets /content/rel_component\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/modelos_estancia/rel_component"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bos6xMz0nl75",
        "outputId": "4aeab2e0-f7cf-46a8-a4c7-5ff08fb4786b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/modelos_estancia/rel_component\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Con ayuda de las siguientes lineas creamos archivos .spacy a partir de archivos json o txt, dichos archivos contienen las entidades asi como las relaciones que utilizamos para entrenar nuestro modelo.\n",
        "\n",
        "\n",
        "Para poder crear los archivos json, es necesario realizar un etiquetado manual utilizando la herramienta ubiai https://ubiai.tools/, despues lo unico que hacemos es descargar los archivos json y transformarlos en archivos .spacy que utilizaremos para entrenar nuestro modelo.\n",
        "\n",
        "Los archivos json los descargamos utilizando"
      ],
      "metadata": {
        "id": "CMAkLmGxpVjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import typer\n",
        "from pathlib import Path\n",
        "from spacy.tokens import Span, DocBin, Doc\n",
        "from spacy.vocab import Vocab\n",
        "from wasabi import Printer\n",
        "from spacy.tokenizer import Tokenizer\n",
        "from spacy.lang.en import English\n",
        "from spacy.lang.es import Spanish\n",
        "from spacy.util import compile_infix_regex\n",
        "import re\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.blank(\"es\")\n",
        "# Create a blank Tokenizer with just the Spanish vocab\n",
        "#Crear un tokenizador en blanco solo con el vocabulario español\n",
        "msg = Printer()\n",
        "SYMM_LABELS = [\"Binds\"]\n",
        "MAP_LABELS = {\n",
        "    \"SEÑALA\": \"SEÑALA\",\n",
        "    \"AGREDIO\": \"AGREDIO\",\n",
        "    \"EN\": \"EN\",\n",
        "    \"ES\": \"ES\",\n",
        "    \"CONEXION\": \"CONEXION\"\n",
        "}\n",
        "\n",
        "\n",
        "ann = \"/content/drive/MyDrive/modelos_estancia/rel_component/rel_test.txt\"\n",
        "train_file='/content/drive/MyDrive/modelos_estancia/rel_component/relations_training.spacy'\n",
        "dev_file=''\n",
        "test_file=''\n",
        "\n",
        "def main(json_loc: Path, train_file: Path, dev_file: Path, test_file: Path):\n",
        "    \"\"\"Creating the corpus from the Prodigy annotations.\"\"\"\n",
        "    Doc.set_extension(\"rel\", default={},force=True)\n",
        "    vocab = Vocab()\n",
        "\n",
        "    docs = {\"train\": [], \"dev\": [], \"test\": [], \"total\": []}\n",
        "    ids = {\"train\": set(), \"dev\": set(), \"test\": set(), \"total\":set()}\n",
        "    count_all = {\"train\": 0, \"dev\": 0, \"test\": 0,\"total\": 0}\n",
        "    count_pos = {\"train\": 0, \"dev\": 0, \"test\": 0,\"total\": 0}\n",
        "\n",
        "    with open(json_loc, encoding=\"utf8\") as jsonfile:\n",
        "        file = json.load(jsonfile)\n",
        "        for example in file:\n",
        "            span_starts = set()\n",
        "            neg = 0\n",
        "            pos = 0\n",
        "                    # Parse the tokens\n",
        "            tokens=nlp(example[\"document\"])    \n",
        "\n",
        "            spaces=[]\n",
        "            spaces = [True if tok.whitespace_ else False for tok in tokens]\n",
        "            words = [t.text for t in tokens]\n",
        "            doc = Doc(nlp.vocab, words=words, spaces=spaces)\n",
        "\n",
        "\n",
        "            # Parse the GGP entities\n",
        "            spans = example[\"tokens\"]\n",
        "            entities = []\n",
        "            span_end_to_start = {}\n",
        "            for span in spans:\n",
        "                entity = doc.char_span(\n",
        "                     span[\"start\"], span[\"end\"], label=span[\"entityLabel\"]\n",
        "                 )\n",
        "\n",
        "                span_end_to_start[span[\"token_start\"]] = span[\"token_start\"]\n",
        "                #print(span_end_to_start)\n",
        "                entities.append(entity)\n",
        "                span_starts.add(span[\"token_start\"])\n",
        "\n",
        "            doc.ents = entities\n",
        "\n",
        "            # Parse the relations\n",
        "            rels = {}\n",
        "            for x1 in span_starts:\n",
        "                for x2 in span_starts:\n",
        "                    rels[(x1, x2)] = {}\n",
        "                    #print(rels)\n",
        "            relations = example[\"relations\"]\n",
        "            #print(len(relations))\n",
        "            for relation in relations:\n",
        "                # the 'head' and 'child' annotations refer to the end token in the span\n",
        "                # but we want the first token\n",
        "                start = span_end_to_start[relation[\"head\"]]\n",
        "                end = span_end_to_start[relation[\"child\"]]\n",
        "                label = relation[\"relationLabel\"]\n",
        "                #print(rels[(start, end)])\n",
        "                #print(label)\n",
        "                #label = MAP_LABELS[label]\n",
        "                if label not in rels[(start, end)]:\n",
        "                    rels[(start, end)][label] = 1.0\n",
        "                    pos += 1\n",
        "                    #print(pos)\n",
        "                    #print(rels[(start, end)])\n",
        "\n",
        "            # The annotation is complete, so fill in zero's where the data is missing\n",
        "            for x1 in span_starts:\n",
        "                for x2 in span_starts:\n",
        "                    for label in MAP_LABELS.values():\n",
        "                        if label not in rels[(x1, x2)]:\n",
        "                            neg += 1\n",
        "                            rels[(x1, x2)][label] = 0.0\n",
        "\n",
        "                            #print(rels[(x1, x2)])\n",
        "            doc._.rel = rels\n",
        "            #print(doc._.rel)\n",
        "\n",
        "            # only keeping documents with at least 1 positive case\n",
        "            if pos > 0:\n",
        "                    docs[\"total\"].append(doc)\n",
        "                    count_pos[\"total\"] += pos\n",
        "                    count_all[\"total\"] += pos + neg\n",
        "\n",
        "                    \n",
        "                    \n",
        "    #print(len(docs[\"total\"]))\n",
        "    docbin = DocBin(docs=docs[\"total\"], store_user_data=True)\n",
        "    docbin.to_disk(train_file)\n",
        "    msg.info(\n",
        "        f\"{len(docs['total'])} training sentences\"\n",
        "    )\n",
        "main(ann, train_file, dev_file, test_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "5YLzS8Q1pMLj",
        "outputId": "0ddb7fa0-6cfe-4ee1-c254-4aa2a5df8240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-0d6f5d19fc4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;34mf\"{len(docs['total'])} training sentences\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     )\n\u001b[0;32m--> 123\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mann\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-0d6f5d19fc4b>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(json_loc, train_file, dev_file, test_file)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mcount_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dev\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"total\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjsonfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjsonfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/modelos_estancia/rel_component/rel_test.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Con los datos de entrenamiento y prueba creados en formato spacy\n",
        "# creamos una carpeta que tiene por nombre 'data', data se ubica en 'rel_component/data',"
      ],
      "metadata": {
        "id": "DrDOkjgGJBfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenar el modelo"
      ],
      "metadata": {
        "id": "XyCrE4SHtdYT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "0. Situarnos en el directorio que tiene por nombre rel_components\n",
        "1. Modificar el path de train, test y dev en archivos project.yml\n",
        "2. Podemos cambiar el modelo en configs/ archivos cgf\n",
        "3. Disminuir max_length en configs/rel_tok2vec.cfg del token predeterminado 100 a 20 \n",
        "> @misc = \"rel_instance_generator.v1\"\n",
        "> max_length = 20"
      ],
      "metadata": {
        "id": "a1dD_PdPtKTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Comenzamos el entrenamiento de nuestro modelo \n",
        "!spacy project run train_cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IS4bbKMRtGE5",
        "outputId": "69b5bd83-2895-41ab-b273-eb3759cc0479"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\n",
            "================================= train_cpu =================================\u001b[0m\n",
            "Running command: /usr/bin/python3 -m spacy train configs/rel_tok2vec.cfg --output training --paths.train data/relations_train.spacy --paths.dev data/relations_test.spacy -c ./scripts/custom_functions.py\n",
            "\u001b[38;5;4mℹ Saving to output directory: training\u001b[0m\n",
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2022-05-30 18:04:28,352] [INFO] Set up nlp object from config\n",
            "[2022-05-30 18:04:28,362] [INFO] Pipeline: ['tok2vec', 'relation_extractor']\n",
            "[2022-05-30 18:04:28,367] [INFO] Created vocabulary\n",
            "[2022-05-30 18:04:28,368] [INFO] Finished initializing nlp object\n",
            "[2022-05-30 18:04:32,676] [INFO] Initialized pipeline components: ['tok2vec', 'relation_extractor']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'relation_extractor']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS RELAT...  REL_MICRO_P  REL_MICRO_R  REL_MICRO_F  SCORE \n",
            "---  ------  ------------  -------------  -----------  -----------  -----------  ------\n",
            "  0       0          0.92           1.98         3.96        25.78         6.86    0.07\n",
            "166     500          8.51          26.74        56.06        28.91        38.14    0.38\n",
            "333    1000          0.34          14.15        56.06        28.91        38.14    0.38\n",
            "\n",
            "Aborted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluar el modelo"
      ],
      "metadata": {
        "id": "tGPyb28VthlG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!spacy project run evaluate"
      ],
      "metadata": {
        "id": "oe9uzZl4tVhd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4de0297-870e-4a07-84a6-443602d0a6c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\n",
            "================================== evaluate ==================================\u001b[0m\n",
            "Running command: /usr/bin/python3 ./scripts/evaluate.py training/model-best data/relations_test.spacy False\n",
            "\n",
            "Random baseline:\n",
            "threshold 0.00 \t {'rel_micro_p': '4.59', 'rel_micro_r': '100.00', 'rel_micro_f': '8.77'}\n",
            "threshold 0.05 \t {'rel_micro_p': '4.51', 'rel_micro_r': '93.75', 'rel_micro_f': '8.61'}\n",
            "threshold 0.10 \t {'rel_micro_p': '4.54', 'rel_micro_r': '89.06', 'rel_micro_f': '8.63'}\n",
            "threshold 0.20 \t {'rel_micro_p': '4.64', 'rel_micro_r': '81.25', 'rel_micro_f': '8.78'}\n",
            "threshold 0.30 \t {'rel_micro_p': '4.71', 'rel_micro_r': '71.09', 'rel_micro_f': '8.83'}\n",
            "threshold 0.40 \t {'rel_micro_p': '4.56', 'rel_micro_r': '59.38', 'rel_micro_f': '8.47'}\n",
            "threshold 0.50 \t {'rel_micro_p': '3.77', 'rel_micro_r': '39.84', 'rel_micro_f': '6.88'}\n",
            "threshold 0.60 \t {'rel_micro_p': '3.72', 'rel_micro_r': '31.25', 'rel_micro_f': '6.65'}\n",
            "threshold 0.70 \t {'rel_micro_p': '3.68', 'rel_micro_r': '22.66', 'rel_micro_f': '6.34'}\n",
            "threshold 0.80 \t {'rel_micro_p': '4.36', 'rel_micro_r': '17.97', 'rel_micro_f': '7.01'}\n",
            "threshold 0.90 \t {'rel_micro_p': '3.45', 'rel_micro_r': '7.81', 'rel_micro_f': '4.78'}\n",
            "threshold 0.99 \t {'rel_micro_p': '0.00', 'rel_micro_r': '0.00', 'rel_micro_f': '0.00'}\n",
            "threshold 1.00 \t {'rel_micro_p': '0.00', 'rel_micro_r': '0.00', 'rel_micro_f': '0.00'}\n",
            "\n",
            "Results of the trained model:\n",
            "threshold 0.00 \t {'rel_micro_p': '4.59', 'rel_micro_r': '100.00', 'rel_micro_f': '8.77'}\n",
            "threshold 0.05 \t {'rel_micro_p': '40.50', 'rel_micro_r': '38.28', 'rel_micro_f': '39.36'}\n",
            "threshold 0.10 \t {'rel_micro_p': '46.00', 'rel_micro_r': '35.94', 'rel_micro_f': '40.35'}\n",
            "threshold 0.20 \t {'rel_micro_p': '48.86', 'rel_micro_r': '33.59', 'rel_micro_f': '39.81'}\n",
            "threshold 0.30 \t {'rel_micro_p': '51.28', 'rel_micro_r': '31.25', 'rel_micro_f': '38.83'}\n",
            "threshold 0.40 \t {'rel_micro_p': '54.29', 'rel_micro_r': '29.69', 'rel_micro_f': '38.38'}\n",
            "threshold 0.50 \t {'rel_micro_p': '56.06', 'rel_micro_r': '28.91', 'rel_micro_f': '38.14'}\n",
            "threshold 0.60 \t {'rel_micro_p': '56.45', 'rel_micro_r': '27.34', 'rel_micro_f': '36.84'}\n",
            "threshold 0.70 \t {'rel_micro_p': '58.33', 'rel_micro_r': '27.34', 'rel_micro_f': '37.23'}\n",
            "threshold 0.80 \t {'rel_micro_p': '60.38', 'rel_micro_r': '25.00', 'rel_micro_f': '35.36'}\n",
            "threshold 0.90 \t {'rel_micro_p': '61.70', 'rel_micro_r': '22.66', 'rel_micro_f': '33.14'}\n",
            "threshold 0.99 \t {'rel_micro_p': '57.14', 'rel_micro_r': '12.50', 'rel_micro_f': '20.51'}\n",
            "threshold 1.00 \t {'rel_micro_p': '60.87', 'rel_micro_r': '10.94', 'rel_micro_f': '18.54'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Para este punto es necesario mover los archivos rel_pipe y rel_model a la carpeta principal rel_model, ya que realizaremos la importación de algunas librerias\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "p2_3t5kjtwy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/modelos_estancia/rel_component"
      ],
      "metadata": {
        "id": "mtDGYXZTuOCz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e830498f-9b2e-48c0-fc13-6cb563175d68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/modelos_estancia/rel_component\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Cargamos nuestro modelo entrenado para identificar entidades\n",
        "#Vease Jupiter Entrenar un modelo de extracción de entidades\n",
        "import spacy\n",
        "nlp = spacy.load(\"/content/drive/MyDrive/modelos_estancia/model-best\", disable = ['parser', 'tagger'])\n",
        "nlp.add_pipe('sentencizer')"
      ],
      "metadata": {
        "id": "uEJSqMoMtVnE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26394b83-2ead-4915-f7c1-ec44fc3a0c8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.pipeline.sentencizer.Sentencizer at 0x7fddfef84e60>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####Cargamos los elementos necesarios para realizar la extracción de entidades\n",
        "####rel_pipe.py y rel_model.py deben moverse o copiarse de la carpeta scripts a \n",
        "####la carpeta rel_component donde es el directorio actual \n",
        "import random\n",
        "import typer\n",
        "from pathlib import Path\n",
        "import spacy\n",
        "from spacy.tokens import DocBin, Doc\n",
        "from spacy.training.example import Example\n",
        "from rel_pipe import make_relation_extractor, score_relations\n",
        "from rel_model import create_relation_model, create_classification_layer, create_instances, create_tensors"
      ],
      "metadata": {
        "id": "ZMI8QCDKuJ2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnMV4DIOObFI"
      },
      "outputs": [],
      "source": [
        "####Cargamos nuestro modelo de extracción de relaciones\n",
        "####que debio de guardarse en la carpeta de nombre training ubicada en la carpeta rel_component\n",
        "nlp2 = spacy.load(\"/content/drive/MyDrive/modelos_estancia/rel_component/training/model-best\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6lJBnwgObFJ"
      },
      "outputs": [],
      "source": [
        "text = [\n",
        "'''\n",
        "El intercambio sobre los datos de homicidios que mantuvieron el periodista Jorge Ramos y el presidente de México, Andrés Manuel López Obrador, el mes pasado, derivó hacia una importante discusión sobre la libertad de expresión, pero a costa de opacar el tema de fondo: México atraviesa el periodo más violento de su historia moderna.\n",
        "La inseguridad ocasionada por el crimen organizado, y que persiste en varias regiones del país, es el principal problema para la producción minera, reconoció Fracisco Quiroga, titular de Minería en la Secretaría de Economía.\n",
        "Las empresas mineras que operan en el país enfrentan inseguridad e ilícitos como los robos de mercancía y la extorsión, por lo que el gobierno federal trabaja con la fuerza pública de los distintos niveles para enfrentarla, dijo el subsecretario de Minería de la Secretaría de Economía, Francisco Quiroga\n",
        "La inseguridad causada por el crimen organizado, que persiste en varias regiones del país, es el principal problema para la producción minera, admitió Francisco Quiroga, subsecretario de Minería.\n",
        "El subsecretario de Minería de la Secretaría de Economía (SE), Francisco Quiroga Fernández, dijo que el sector enfrenta delitos como robos y extorsión, sin embargo, ya trabajan en abatir esta problemática.\n",
        "'''\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for doc in nlp.pipe(text, disable=[\"tagger\", \"parser\"]):\n",
        "    print([(ent.text, ent.label_) for ent in doc.ents])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmFaNAPuO49L",
        "outputId": "db40e06d-c0d0-4823-8705-d6740ee068b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Jorge Ramos', 'PERSONAS'), ('presidente', 'PUESTOSDETRABAJO'), ('Andrés Manuel López Obrador', 'PERSONAS'), ('crimen organizado', 'OTROS'), ('Fracisco Quiroga', 'PERSONAS'), ('titular', 'PUESTOSDETRABAJO'), ('Secretaría de Economía', 'ORGANIZACIONES'), ('subsecretario', 'PUESTOSDETRABAJO'), ('Secretaría de Economía', 'ORGANIZACIONES'), ('Francisco Quiroga', 'PERSONAS'), ('crimen organizado', 'OTROS'), ('Francisco Quiroga', 'PERSONAS'), ('subsecretario', 'PUESTOSDETRABAJO'), ('subsecretario de Minería de la Secretaría de Economía (SE)', 'PUESTOSDETRABAJO'), ('Francisco Quiroga Fernández', 'PERSONAS')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Tomamos las entidades generadas del modelo reconocimiento de entidades \n",
        "##y son las entradas a al modelo de relaciones \n",
        "for name, proc in nlp2.pipeline[:]:\n",
        "          print(1)\n",
        "          doc = proc(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r31wzrrqO-N4",
        "outputId": "94927154-3946-4595-9dd7-4e45a3b23512"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuWVisVZObFL"
      },
      "outputs": [],
      "source": [
        "for value, rel_dict in doc._.rel.items():\n",
        "        for sent in doc.sents:\n",
        "          for e in sent.ents:\n",
        "            for b in sent.ents:\n",
        "              if e.start == value[0] and b.start == value[1]:\n",
        "                if rel_dict['AGREDIO'] >=0.005 :\n",
        "                  print(f\" entities: {e.text, b.text} --> predicted relation: {rel_dict}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBK_fA5gEaQ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc10a415-0768-4c75-c92d-3c048f8d176e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " entities: ('Francisco Quiroga', 'crimen organizado') --> predicted relation: {'SEÑALA': 0.14460193, 'AGREDIO': 0.00024804816, 'EN': 2.0611535e-09, 'ES': 0.005892892, 'CONEXION': 8.046362e-08}\n"
          ]
        }
      ],
      "source": [
        "for value, rel_dict in doc._.rel.items():\n",
        "        for sent in doc.sents:\n",
        "          for e in sent.ents:\n",
        "            for b in sent.ents:\n",
        "              if e.start == value[0] and b.start == value[1]:\n",
        "                if rel_dict['SEÑALA'] >=0.005 :\n",
        "                  print(f\" entities: {e.text, b.text} --> predicted relation: {rel_dict}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-21z4Y3YEaTc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b003d552-5497-4db5-9fee-bbe83a16619a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " entities: ('Jorge Ramos', 'Andrés Manuel López Obrador') --> predicted relation: {'SEÑALA': 1.13628175e-05, 'AGREDIO': 3.111034e-05, 'EN': 2.0611535e-09, 'ES': 0.001975511, 'CONEXION': 0.22109523}\n",
            " entities: ('Secretaría de Economía', 'Fracisco Quiroga') --> predicted relation: {'SEÑALA': 4.284274e-07, 'AGREDIO': 0.0001659334, 'EN': 2.0611535e-09, 'ES': 1.2524188e-07, 'CONEXION': 0.0008763566}\n",
            " entities: ('Secretaría de Economía', 'subsecretario') --> predicted relation: {'SEÑALA': 1.890733e-08, 'AGREDIO': 8.529301e-07, 'EN': 2.0611535e-09, 'ES': 0.003582913, 'CONEXION': 0.0008183951}\n"
          ]
        }
      ],
      "source": [
        "for value, rel_dict in doc._.rel.items():\n",
        "        for sent in doc.sents:\n",
        "          for e in sent.ents:\n",
        "            for b in sent.ents:\n",
        "              if e.start == value[0] and b.start == value[1]:\n",
        "                if rel_dict['CONEXION'] >=0.0005 :\n",
        "                  print(f\" entities: {e.text, b.text} --> predicted relation: {rel_dict}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for value, rel_dict in doc._.rel.items():\n",
        "        for sent in doc.sents:\n",
        "          for e in sent.ents:\n",
        "            for b in sent.ents:\n",
        "              if e.start == value[0] and b.start == value[1]:\n",
        "                if rel_dict['ES'] >=0.5 :\n",
        "                  print(f\" entities: {e.text, b.text} --> predicted relation: {rel_dict}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "na24mvXz9K7d",
        "outputId": "cda78f7b-e82d-44a1-ae23-4e7a02a84b43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " entities: ('Andrés Manuel López Obrador', 'presidente') --> predicted relation: {'SEÑALA': 8.9756696e-07, 'AGREDIO': 5.536075e-09, 'EN': 2.0611535e-09, 'ES': 0.9997402, 'CONEXION': 2.0611535e-09}\n",
            " entities: ('Fracisco Quiroga', 'titular') --> predicted relation: {'SEÑALA': 0.0003780298, 'AGREDIO': 4.0036937e-07, 'EN': 7.880128e-08, 'ES': 0.51306117, 'CONEXION': 1.6992441e-08}\n",
            " entities: ('Francisco Quiroga', 'subsecretario') --> predicted relation: {'SEÑALA': 6.406767e-07, 'AGREDIO': 5.8838407e-07, 'EN': 2.0611535e-09, 'ES': 0.9989825, 'CONEXION': 7.231341e-07}\n",
            " entities: ('Francisco Quiroga', 'subsecretario') --> predicted relation: {'SEÑALA': 2.375778e-07, 'AGREDIO': 7.183829e-06, 'EN': 2.0611535e-09, 'ES': 0.99987257, 'CONEXION': 1.9590213e-06}\n"
          ]
        }
      ]
    }
  ]
}